\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{mutlu}
\citation{anderson}
\citation{mutlu}
\citation{kim}
\citation{mutlu}
\citation{mutlu}
\citation{kim}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A photo of a pH strip captured with a hand-held smartphone under standard household lighting. This pH strip was submersed in a buffer with a target pH value of 8.70. The wet pH strip occasionally had solution leak across panels.}}{1}{figure.1}}
\newlabel{raw_photo}{{1}{1}{A photo of a pH strip captured with a hand-held smartphone under standard household lighting. This pH strip was submersed in a buffer with a target pH value of 8.70. The wet pH strip occasionally had solution leak across panels}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Experimental Setup and Pre-Processing}{1}{section.2}}
\citation{farid}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Image preprocessing procedure: (A) Horizontal Sobel filter applied on a grayscaled pH strip image. The red lines represent the regions to crop the image at. (B) Vertical Sobel filter applied on a grayscaled pH strip image. The red lines represent the regions to crop the image at. (C) Binarized mask of the original image, cropped based on the Sobel filters, and eroded to get the center color regions. (D) Final masked image, isolating the four color squares.}}{2}{figure.2}}
\newlabel{pre-process}{{2}{2}{Image preprocessing procedure: (A) Horizontal Sobel filter applied on a grayscaled pH strip image. The red lines represent the regions to crop the image at. (B) Vertical Sobel filter applied on a grayscaled pH strip image. The red lines represent the regions to crop the image at. (C) Binarized mask of the original image, cropped based on the Sobel filters, and eroded to get the center color regions. (D) Final masked image, isolating the four color squares}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (A) The colors extracted from the four panels of a pH strip, stored in code as a total of 12 RGB values. (B) Gamma correction with a parameter of 1.5 applied on the raw extracted colors. Gamma correction nonlinear maps each color to effectively lighten or darken the image. (C) Hue rotation of -60 degrees around the color wheel applied on the raw extracted colors. (D) Application of both a gamma correction of 1.5 and a hue rotation of -60 degrees on the raw extracted colors.}}{2}{figure.3}}
\newlabel{four-colors}{{3}{2}{(A) The colors extracted from the four panels of a pH strip, stored in code as a total of 12 RGB values. (B) Gamma correction with a parameter of 1.5 applied on the raw extracted colors. Gamma correction nonlinear maps each color to effectively lighten or darken the image. (C) Hue rotation of -60 degrees around the color wheel applied on the raw extracted colors. (D) Application of both a gamma correction of 1.5 and a hue rotation of -60 degrees on the raw extracted colors}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Raw color extracted data projected onto two orthogonal axes such that variance captured is maximized.}}{3}{figure.4}}
\newlabel{pca}{{4}{3}{Raw color extracted data projected onto two orthogonal axes such that variance captured is maximized}{figure.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Results}{3}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Pre-Processing}{3}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Classification Models}{3}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Support Vector Machine Classification Model. The Y axis is the Accuracy (percent of predicted labels that are correct) and the X axis is the regularization strength. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation.}}{3}{figure.5}}
\newlabel{svm}{{5}{3}{Support Vector Machine Classification Model. The Y axis is the Accuracy (percent of predicted labels that are correct) and the X axis is the regularization strength. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Sample confusion matrix for one fold of three-fold cross validation for SVM model. The confusion matrix plots the predicted class on the X axis, and the true class on the Y axis. Therefore, elements along the diagonal of the matrix were predicted correctly. In this case, 2 of 27 images were misclassified.}}{3}{figure.6}}
\newlabel{svm_confusion}{{6}{3}{Sample confusion matrix for one fold of three-fold cross validation for SVM model. The confusion matrix plots the predicted class on the X axis, and the true class on the Y axis. Therefore, elements along the diagonal of the matrix were predicted correctly. In this case, 2 of 27 images were misclassified}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Regression Models}{3}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Linear Discriminant Analysis Classification Model. The Y axis is the Accuracy (percent of predicted labels that are correct) and the X axis is different number of components we project the data onto when doing PCA. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation.}}{4}{figure.7}}
\newlabel{lda}{{7}{4}{Linear Discriminant Analysis Classification Model. The Y axis is the Accuracy (percent of predicted labels that are correct) and the X axis is different number of components we project the data onto when doing PCA. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Sample confusion matrix for one fold of three-fold cross validation for LDA model. None of the images were misclassified in this fold.}}{4}{figure.8}}
\newlabel{lda_confusion}{{8}{4}{Sample confusion matrix for one fold of three-fold cross validation for LDA model. None of the images were misclassified in this fold}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces K Nearest Neighbor Classification Model. The Y axis is the Accuracy (percent of predicted labels that are correct) and the X axis is the number of neighbors used in the model. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation.}}{4}{figure.9}}
\newlabel{knn}{{9}{4}{K Nearest Neighbor Classification Model. The Y axis is the Accuracy (percent of predicted labels that are correct) and the X axis is the number of neighbors used in the model. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Sample confusion matrix for one fold of three-fold cross validation for kNN model (without PCA/scaling). 2 of 35 images were misclassified.}}{4}{figure.10}}
\newlabel{knn_confusion}{{10}{4}{Sample confusion matrix for one fold of three-fold cross validation for kNN model (without PCA/scaling). 2 of 35 images were misclassified}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces K Nearest Neighbor Classification Model, with PCA and scaling preprocessing. The Y axis is the Accuracy (percent of predicted labels that are correct) and the X axis is the number of neighbors used in the model. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation.}}{4}{figure.11}}
\newlabel{knn_pca}{{11}{4}{K Nearest Neighbor Classification Model, with PCA and scaling preprocessing. The Y axis is the Accuracy (percent of predicted labels that are correct) and the X axis is the number of neighbors used in the model. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Ridge Regression Model. The Y axis is the Mean Squared Error, which is ${\begingroup 1\endgroup \over n} \Sigma _{i=1}^n (Y_i - \mathaccent "705E\relax {Y}_i)^2$ where $Y_i$ is the true value of strip $i$ and $\mathaccent "705E\relax {Y}_i$ is the predicted value from our model of strip $i$, and the X axis is different levels of regularization on the model, shown on a logarithmic scale from $-3$ to $1$. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation.}}{5}{figure.12}}
\newlabel{ridge}{{12}{5}{Ridge Regression Model. The Y axis is the Mean Squared Error, which is $\frac {1}{n} \Sigma _{i=1}^n (Y_i - \hat {Y}_i)^2$ where $Y_i$ is the true value of strip $i$ and $\hat {Y}_i$ is the predicted value from our model of strip $i$, and the X axis is different levels of regularization on the model, shown on a logarithmic scale from $-3$ to $1$. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces K Nearest Neighbor Regression Model. The Y axis is the Mean Squared Error and the X axis is the number of neighbors used in the model. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation.}}{5}{figure.13}}
\newlabel{Rknn}{{13}{5}{K Nearest Neighbor Regression Model. The Y axis is the Mean Squared Error and the X axis is the number of neighbors used in the model. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces K Nearest Neighbor Regression Model, with PCA and scaling preprocessing. The Y axis is the Mean Squared Error and the X axis is the number of neighbors used in the model. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation.}}{5}{figure.14}}
\newlabel{Rknn_pca}{{14}{5}{K Nearest Neighbor Regression Model, with PCA and scaling preprocessing. The Y axis is the Mean Squared Error and the X axis is the number of neighbors used in the model. The four lines represent the four datasets we used: no color change, with gamma modification, with color rotation, and with both gamma modification and color rotation}{figure.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Discussion}{5}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Classification}{5}{subsection.4.1}}
\citation{product}
\bibcite{anderson}{1}
\bibcite{mutlu}{2}
\bibcite{kim}{3}
\bibcite{farid}{4}
\bibcite{product}{5}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Regression}{6}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Acknowledging Shortcomings}{6}{subsection.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{6}{section.5}}
\@writefile{toc}{\contentsline {section}{References}{6}{section*.2}}
